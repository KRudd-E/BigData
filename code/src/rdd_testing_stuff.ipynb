{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9063d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import DataFrame\n",
    "from aeon.classification.distance_based import ProximityTree, ProximityForest\n",
    "import logging\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from data_ingestion import DataIngestion\n",
    "from preprocessing import Preprocessor\n",
    "from prediction_manager import PredictionManager\n",
    "from local_model_manager import LocalModelManager\n",
    "from evaluation import Evaluator\n",
    "from utilities import show_compact\n",
    "import time\n",
    "import json\n",
    "from random import sample\n",
    "from dtaidistance import dtw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d01e9ea",
   "metadata": {},
   "source": [
    "## ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84413ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"GenericRDD\").getOrCreate()\n",
    "\n",
    "# Access the SparkContext\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a5f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"ID\": 1, \"Name\": \"Alice\", \"Age\": 25, \"Capacity\": 50},\n",
    "    {\"ID\": 2, \"Name\": \"Bob\", \"Age\": 30, \"Capacity\": 30},\n",
    "    {\"ID\": 3, \"Name\": \"Charlie\", \"Age\": 35, \"Capacity\": 70},\n",
    "    {\"ID\": 4, \"Name\": \"David\", \"Age\": 40, \"Capacity\": 20},\n",
    "    {\"ID\": 5, \"Name\": \"Eve\", \"Age\": 45, \"Capacity\": 40}\n",
    "]\n",
    "\n",
    "rdd = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25f25c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ID': 1, 'Name': 'Alice', 'Age': 25, 'Capacity': 50}, {'ID': 2, 'Name': 'Bob', 'Age': 30, 'Capacity': 30}, {'ID': 3, 'Name': 'Charlie', 'Age': 35, 'Capacity': 70}, {'ID': 4, 'Name': 'David', 'Age': 40, 'Capacity': 20}, {'ID': 5, 'Name': 'Eve', 'Age': 45, 'Capacity': 40}]\n"
     ]
    }
   ],
   "source": [
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b16a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ID': 1, 'Name': 'Alice', 'Age': 25, 'Capacity': 50, 'Score': 100}, {'ID': 2, 'Name': 'Bob', 'Age': 30, 'Capacity': 30, 'Score': 60}, {'ID': 3, 'Name': 'Charlie', 'Age': 35, 'Capacity': 70, 'Score': 140}, {'ID': 4, 'Name': 'David', 'Age': 40, 'Capacity': 20, 'Score': 40}, {'ID': 5, 'Name': 'Eve', 'Age': 45, 'Capacity': 40, 'Score': 80}]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column \"Score\" with some computed or static value\n",
    "new_rdd = rdd.map(lambda row: {**row, \"Score\": row[\"Capacity\"] * 2})\n",
    "\n",
    "# Show the updated RDD\n",
    "print(new_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e36c296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 1, 'Name': 'Alice', 'Age': 25, 'Capacity': 50, 'Label': 1}\n",
      "{'ID': 2, 'Name': 'Bob', 'Age': 30, 'Capacity': 30, 'Label': 0}\n",
      "{'ID': 3, 'Name': 'Charlie', 'Age': 35, 'Capacity': 70, 'Label': 1}\n",
      "{'ID': 4, 'Name': 'David', 'Age': 40, 'Capacity': 20, 'Label': 0}\n",
      "{'ID': 5, 'Name': 'Eve', 'Age': 45, 'Capacity': 40, 'Label': 0}\n"
     ]
    }
   ],
   "source": [
    "labeled_rdd = rdd.map(lambda row: {**row, \"Label\": 1 if row[\"Capacity\"] > 40 else 0})\n",
    "\n",
    "for row in labeled_rdd.collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a0e00",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"label\": 1, \"time_series\": [1.0, 2.1, 3.2, 4.3, 5.4]},\n",
    "    {\"label\": 2, \"time_series\": [2.0, 3.1, 4.2, 5.3, 6.4]},\n",
    "    {\"label\": 3, \"time_series\": [3.0, 4.1, 5.2, 6.3, 7.4]},\n",
    "    {\"label\": 4, \"time_series\": [4.0, 5.1, 6.2, 7.3, 8.4]},\n",
    "    {\"label\": 1, \"time_series\": [1.5, 2.6, 3.7, 4.8, 5.9]},\n",
    "    {\"label\": 2, \"time_series\": [2.5, 3.6, 4.7, 5.8, 6.9]},\n",
    "    {\"label\": 3, \"time_series\": [3.5, 4.6, 5.7, 6.8, 7.9]},\n",
    "    {\"label\": 4, \"time_series\": [4.5, 5.6, 6.7, 7.8, 8.9]}\n",
    "]\n",
    "\n",
    "rdd = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cae169e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd.repartition(1)\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1967f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.5, 3.6, 4.7, 5.8, 6.9]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = rdd.sample(False, 0.5).collect()\n",
    "lst[0]['time_series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc7f8c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 4, 'time_series': [4.0, 5.1, 6.2, 7.3, 8.4], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9]}\n",
      "{'label': 2, 'time_series': [2.5, 3.6, 4.7, 5.8, 6.9], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9]}\n",
      "{'label': 2, 'time_series': [2.0, 3.1, 4.2, 5.3, 6.4], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9]}\n",
      "{'label': 3, 'time_series': [3.0, 4.1, 5.2, 6.3, 7.4], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9]}\n",
      "{'label': 1, 'time_series': [1.5, 2.6, 3.7, 4.8, 5.9], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9]}\n",
      "{'label': 3, 'time_series': [3.5, 4.6, 5.7, 6.8, 7.9], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9]}\n",
      "{'label': 1, 'time_series': [1.0, 2.1, 3.2, 4.3, 5.4], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9]}\n",
      "{'label': 4, 'time_series': [4.5, 5.6, 6.7, 7.8, 8.9], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9]}\n"
     ]
    }
   ],
   "source": [
    "def sample_and_add_column(iterator):\n",
    "    partition_data = list(iterator)\n",
    "    sampled_element = sample(partition_data, 1)[0]['time_series']\n",
    "    return iter([{**row, \"exemplar\": sampled_element} for row in partition_data])\n",
    "\n",
    "rdd_with_sampled_column = rdd.mapPartitions(sample_and_add_column)\n",
    "\n",
    "# Collect and print the updated RDD\n",
    "for row in rdd_with_sampled_column.collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bd9ff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 4, 'time_series': [4.0, 5.1, 6.2, 7.3, 8.4], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9], 'dtw_distance': 4.085339643163099}\n",
      "{'label': 2, 'time_series': [2.5, 3.6, 4.7, 5.8, 6.9], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9], 'dtw_distance': 1.42828568570857}\n",
      "{'label': 2, 'time_series': [2.0, 3.1, 4.2, 5.3, 6.4], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9], 'dtw_distance': 1.118033988749895}\n",
      "{'label': 3, 'time_series': [3.0, 4.1, 5.2, 6.3, 7.4], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9], 'dtw_distance': 2.2671568097509267}\n",
      "{'label': 1, 'time_series': [1.5, 2.6, 3.7, 4.8, 5.9], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9], 'dtw_distance': 0.0}\n",
      "{'label': 3, 'time_series': [3.5, 4.6, 5.7, 6.8, 7.9], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9], 'dtw_distance': 3.1208973068654466}\n",
      "{'label': 1, 'time_series': [1.0, 2.1, 3.2, 4.3, 5.4], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9], 'dtw_distance': 1.118033988749895}\n",
      "{'label': 4, 'time_series': [4.5, 5.6, 6.7, 7.8, 8.9], 'exemplar': [1.5, 2.6, 3.7, 4.8, 5.9], 'dtw_distance': 5.165268628057984}\n"
     ]
    }
   ],
   "source": [
    "# def calc_dtw_distance(iterator):\n",
    "#     partition_data = list(iterator)\n",
    "#     time_series = partition_data['time_series']\n",
    "#     exemplar = partition_data['exemplar']\n",
    "#     dtw_distance = dtw.distance(time_series, exemplar)\n",
    "#     return iter([{**row, \"dtw_distance\": dtw_distance} for row in partition_data])\n",
    "\n",
    "def calc_dtw_distance(iterator):\n",
    "    partition_data = list(iterator)\n",
    "    updated_rows = []\n",
    "    \n",
    "    for row in partition_data:\n",
    "        # Access the time_series and exemplar fields for each row\n",
    "        time_series = row['time_series']\n",
    "        exemplar = row['exemplar']\n",
    "        \n",
    "        # Calculate the DTW distance\n",
    "        dtw_distance = dtw.distance(time_series, exemplar)\n",
    "        \n",
    "        # Add the DTW distance as a new column\n",
    "        updated_row = {**row, \"dtw_distance\": dtw_distance}\n",
    "        updated_rows.append(updated_row)\n",
    "    \n",
    "    return iter(updated_rows)\n",
    "\n",
    "rdd_with_dtw = rdd_with_sampled_column.mapPartitions(calc_dtw_distance)\n",
    "\n",
    "for row in rdd_with_dtw.collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e885f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
