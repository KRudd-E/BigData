{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc7c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import DataFrame\n",
    "from aeon.classification.distance_based import ProximityTree, ProximityForest\n",
    "import logging\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from data_ingestion import DataIngestion\n",
    "from preprocessing import Preprocessor\n",
    "from prediction_manager import PredictionManager\n",
    "from local_model_manager import LocalModelManager\n",
    "from evaluation import Evaluator\n",
    "from utilities import show_compact\n",
    "import time\n",
    "import json\n",
    "from random import sample\n",
    "from dtaidistance import dtw\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"GenericRDD\").getOrCreate()\n",
    "\n",
    "# Access the SparkContext\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f30b2552",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdata = [\n",
    "    {'label': 1, 'time_series': [1.2, 2.4, 3.6, 4.8, 6.0]},\n",
    "    {'label': 1, 'time_series': [1.0, 1.8, 2.6, 3.4, 4.2]},\n",
    "    {'label': 1, 'time_series': [0.9, 1.8, 2.7, 3.6, 4.5]},\n",
    "    {'label': 1, 'time_series': [1.5, 2.1, 2.7, 3.3, 3.9]},\n",
    "    {'label': 1, 'time_series': [0.8, 1.7, 2.5, 3.2, 4.0]},\n",
    "    {'label': 2, 'time_series': [2.1, 3.3, 4.5, 5.7, 6.9]},\n",
    "    {'label': 2, 'time_series': [3.0, 3.8, 4.6, 5.4, 6.2]},\n",
    "    {'label': 2, 'time_series': [3.3, 4.1, 4.9, 5.7, 6.5]},\n",
    "    {'label': 3, 'time_series': [0.5, 1.5, 2.5, 3.5, 4.5]},\n",
    "    {'label': 3, 'time_series': [2.0, 2.5, 3.0, 3.5, 4.0]},\n",
    "    {'label': 4, 'time_series': [5.5, 6.6, 7.7, 8.8, 9.9]},\n",
    "    {'label': 4, 'time_series': [6.1, 6.2, 6.3, 6.4, 6.5]},\n",
    "    {'label': 1, 'time_series': [0.7, 1.3, 1.9, 2.5, 3.1]},\n",
    "    {'label': 1, 'time_series': [1.1, 2.1, 3.1, 4.1, 5.1]},\n",
    "    {'label': 1, 'time_series': [0.6, 1.2, 1.8, 2.4, 3.0]},\n",
    "    {'label': 2, 'time_series': [2.4, 3.5, 4.6, 5.7, 6.8]},\n",
    "    {'label': 2, 'time_series': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
    "    {'label': 3, 'time_series': [1.0, 1.8, 2.6, 3.4, 4.2]},\n",
    "    {'label': 4, 'time_series': [6.0, 7.0, 8.0, 9.0, 10.0]},\n",
    "    {'label': 1, 'time_series': [1.3, 2.3, 3.3, 4.3, 5.3]},\n",
    "    {'label': 1, 'time_series': [0.9, 1.4, 1.9, 2.4, 2.9]},\n",
    "    {'label': 1, 'time_series': [1.4, 2.0, 2.6, 3.2, 3.8]},\n",
    "    {'label': 2, 'time_series': [2.2, 3.1, 4.0, 4.9, 5.8]},\n",
    "    {'label': 2, 'time_series': [2.6, 3.2, 3.8, 4.4, 5.0]},\n",
    "    {'label': 3, 'time_series': [1.2, 2.0, 2.8, 3.6, 4.4]},\n",
    "    {'label': 3, 'time_series': [0.6, 1.3, 2.0, 2.7, 3.4]},\n",
    "    {'label': 4, 'time_series': [6.3, 6.5, 6.7, 6.9, 7.1]},\n",
    "    {'label': 4, 'time_series': [7.0, 7.8, 8.6, 9.4, 10.2]},\n",
    "    {'label': 4, 'time_series': [6.5, 7.0, 7.5, 8.0, 8.5]},\n",
    "    {'label': 1, 'time_series': [0.5, 1.0, 1.5, 2.0, 2.5]},\n",
    "    {'label': 2, 'time_series': [0.6, 1.4, 1.3, 2.1, 2.5]},\n",
    "    {'label': 3, 'time_series': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
    "    {'label': 4, 'time_series': [0.2, 1.9, 1.6, 2.3, 2.7]},\n",
    "    {'label': 4, 'time_series': [0.9, 1.7, 1.2, 2.4, 2.8]}\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(tsdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e669a74f",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee4551f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 3, 'time_series': [0.5, 1.5, 2.5, 3.5, 4.5], 'partition_id': 0},\n",
       " {'label': 3, 'time_series': [2.0, 2.5, 3.0, 3.5, 4.0], 'partition_id': 0},\n",
       " {'label': 4, 'time_series': [5.5, 6.6, 7.7, 8.8, 9.9], 'partition_id': 0},\n",
       " {'label': 4, 'time_series': [6.1, 6.2, 6.3, 6.4, 6.5], 'partition_id': 0},\n",
       " {'label': 1, 'time_series': [0.7, 1.3, 1.9, 2.5, 3.1], 'partition_id': 0},\n",
       " {'label': 1, 'time_series': [1.1, 2.1, 3.1, 4.1, 5.1], 'partition_id': 0},\n",
       " {'label': 1, 'time_series': [0.6, 1.2, 1.8, 2.4, 3.0], 'partition_id': 0},\n",
       " {'label': 2, 'time_series': [2.4, 3.5, 4.6, 5.7, 6.8], 'partition_id': 0},\n",
       " {'label': 2, 'time_series': [1.9, 2.8, 3.7, 4.6, 5.5], 'partition_id': 0},\n",
       " {'label': 3, 'time_series': [1.0, 1.8, 2.6, 3.4, 4.2], 'partition_id': 0},\n",
       " {'label': 4, 'time_series': [6.0, 7.0, 8.0, 9.0, 10.0], 'partition_id': 0},\n",
       " {'label': 1, 'time_series': [1.3, 2.3, 3.3, 4.3, 5.3], 'partition_id': 0},\n",
       " {'label': 1, 'time_series': [0.9, 1.4, 1.9, 2.4, 2.9], 'partition_id': 0},\n",
       " {'label': 1, 'time_series': [1.4, 2.0, 2.6, 3.2, 3.8], 'partition_id': 0},\n",
       " {'label': 2, 'time_series': [2.2, 3.1, 4.0, 4.9, 5.8], 'partition_id': 0},\n",
       " {'label': 2, 'time_series': [2.6, 3.2, 3.8, 4.4, 5.0], 'partition_id': 0},\n",
       " {'label': 3, 'time_series': [1.2, 2.0, 2.8, 3.6, 4.4], 'partition_id': 0},\n",
       " {'label': 3, 'time_series': [0.6, 1.3, 2.0, 2.7, 3.4], 'partition_id': 0},\n",
       " {'label': 4, 'time_series': [6.3, 6.5, 6.7, 6.9, 7.1], 'partition_id': 0},\n",
       " {'label': 4, 'time_series': [7.0, 7.8, 8.6, 9.4, 10.2], 'partition_id': 0},\n",
       " {'label': 1, 'time_series': [1.2, 2.4, 3.6, 4.8, 6.0], 'partition_id': 1},\n",
       " {'label': 1, 'time_series': [1.0, 1.8, 2.6, 3.4, 4.2], 'partition_id': 1},\n",
       " {'label': 1, 'time_series': [0.9, 1.8, 2.7, 3.6, 4.5], 'partition_id': 1},\n",
       " {'label': 1, 'time_series': [1.5, 2.1, 2.7, 3.3, 3.9], 'partition_id': 1},\n",
       " {'label': 1, 'time_series': [0.8, 1.7, 2.5, 3.2, 4.0], 'partition_id': 1},\n",
       " {'label': 2, 'time_series': [2.1, 3.3, 4.5, 5.7, 6.9], 'partition_id': 1},\n",
       " {'label': 2, 'time_series': [3.0, 3.8, 4.6, 5.4, 6.2], 'partition_id': 1},\n",
       " {'label': 2, 'time_series': [3.3, 4.1, 4.9, 5.7, 6.5], 'partition_id': 1},\n",
       " {'label': 4, 'time_series': [6.5, 7.0, 7.5, 8.0, 8.5], 'partition_id': 1},\n",
       " {'label': 1, 'time_series': [0.5, 1.0, 1.5, 2.0, 2.5], 'partition_id': 1},\n",
       " {'label': 2, 'time_series': [0.6, 1.4, 1.3, 2.1, 2.5], 'partition_id': 1},\n",
       " {'label': 3, 'time_series': [0.3, 1.7, 1.6, 2.2, 2.6], 'partition_id': 1},\n",
       " {'label': 4, 'time_series': [0.2, 1.9, 1.6, 2.3, 2.7], 'partition_id': 1},\n",
       " {'label': 4, 'time_series': [0.9, 1.7, 1.2, 2.4, 2.8], 'partition_id': 1}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repartition_sparkdf(df, num_partitions):\n",
    "    rdd = df.rdd\n",
    "    rdd = rdd.repartition(num_partitions)\n",
    "    rdd = rdd.mapPartitionsWithIndex(\n",
    "            lambda idx, iter: [{**row.asDict(), \"partition_id\": idx} for row in iter]\n",
    "        )\n",
    "    return rdd\n",
    "\n",
    "# example usage\n",
    "rdd = repartition_sparkdf(df, 2)\n",
    "print(rdd.getNumPartitions())  # should print 1\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be92f01",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ee6bc902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 3,\n",
       "  'time_series': [2.0, 2.5, 3.0, 3.5, 4.0],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 4,\n",
       "  'time_series': [5.5, 6.6, 7.7, 8.8, 9.9],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 4,\n",
       "  'time_series': [6.1, 6.2, 6.3, 6.4, 6.5],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.7, 1.3, 1.9, 2.5, 3.1],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 1,\n",
       "  'time_series': [1.1, 2.1, 3.1, 4.1, 5.1],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.6, 1.2, 1.8, 2.4, 3.0],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 2,\n",
       "  'time_series': [2.4, 3.5, 4.6, 5.7, 6.8],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 3,\n",
       "  'time_series': [1.0, 1.8, 2.6, 3.4, 4.2],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 1,\n",
       "  'time_series': [1.3, 2.3, 3.3, 4.3, 5.3],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.9, 1.4, 1.9, 2.4, 2.9],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 2,\n",
       "  'time_series': [2.2, 3.1, 4.0, 4.9, 5.8],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 2,\n",
       "  'time_series': [2.6, 3.2, 3.8, 4.4, 5.0],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 3,\n",
       "  'time_series': [1.2, 2.0, 2.8, 3.6, 4.4],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 3,\n",
       "  'time_series': [0.6, 1.3, 2.0, 2.7, 3.4],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 4,\n",
       "  'time_series': [6.3, 6.5, 6.7, 6.9, 7.1],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 4,\n",
       "  'time_series': [7.0, 7.8, 8.6, 9.4, 10.2],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 1,\n",
       "  'time_series': [1.0, 1.8, 2.6, 3.4, 4.2],\n",
       "  'partition_id': 1,\n",
       "  'exemplar_1': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_2': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_3': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_4': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.9, 1.8, 2.7, 3.6, 4.5],\n",
       "  'partition_id': 1,\n",
       "  'exemplar_1': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_2': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_3': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_4': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
       " {'label': 1,\n",
       "  'time_series': [1.5, 2.1, 2.7, 3.3, 3.9],\n",
       "  'partition_id': 1,\n",
       "  'exemplar_1': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_2': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_3': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_4': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.8, 1.7, 2.5, 3.2, 4.0],\n",
       "  'partition_id': 1,\n",
       "  'exemplar_1': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_2': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_3': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_4': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
       " {'label': 2,\n",
       "  'time_series': [2.1, 3.3, 4.5, 5.7, 6.9],\n",
       "  'partition_id': 1,\n",
       "  'exemplar_1': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_2': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_3': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_4': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
       " {'label': 2,\n",
       "  'time_series': [3.0, 3.8, 4.6, 5.4, 6.2],\n",
       "  'partition_id': 1,\n",
       "  'exemplar_1': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_2': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_3': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_4': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
       " {'label': 4,\n",
       "  'time_series': [6.5, 7.0, 7.5, 8.0, 8.5],\n",
       "  'partition_id': 1,\n",
       "  'exemplar_1': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_2': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_3': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_4': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.5, 1.0, 1.5, 2.0, 2.5],\n",
       "  'partition_id': 1,\n",
       "  'exemplar_1': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_2': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_3': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_4': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
       " {'label': 2,\n",
       "  'time_series': [0.6, 1.4, 1.3, 2.1, 2.5],\n",
       "  'partition_id': 1,\n",
       "  'exemplar_1': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_2': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_3': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_4': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
       " {'label': 4,\n",
       "  'time_series': [0.2, 1.9, 1.6, 2.3, 2.7],\n",
       "  'partition_id': 1,\n",
       "  'exemplar_1': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_2': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_3': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_4': [0.3, 1.7, 1.6, 2.2, 2.6]}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_exemplars(iterator):\n",
    "    partition_data = list(iterator)\n",
    "    if not partition_data:\n",
    "        return iter([])\n",
    "    \n",
    "    # Group data by class\n",
    "    grouped_data_by_class = {}\n",
    "    for row in partition_data:\n",
    "        label = row.get('label')\n",
    "        if label is not None:\n",
    "            grouped_data_by_class.setdefault(label, []).append(row)\n",
    "    \n",
    "    # Select one exemplar per class\n",
    "    chosen_exemplars = []\n",
    "    for label, instances in grouped_data_by_class.items():\n",
    "        if instances:  # Ensure there are instances for the class\n",
    "            exemplar = sample(instances, 1)[0]\n",
    "            chosen_exemplars.append(exemplar['time_series'])\n",
    "    \n",
    "    # Remove chosen exemplars from the working data\n",
    "    filtered_partition = [\n",
    "        row for row in partition_data\n",
    "        if row['time_series'] not in chosen_exemplars\n",
    "    ]\n",
    "    \n",
    "    # Return rows with individual exemplar columns\n",
    "    result = []\n",
    "    for row in filtered_partition:\n",
    "        new_row = {**row}\n",
    "        # Add each exemplar as its own column\n",
    "        for i, exemplar in enumerate(chosen_exemplars):\n",
    "            new_row[f\"exemplar_{i+1}\"] = exemplar\n",
    "        result.append(new_row)\n",
    "    \n",
    "    return iter(result)\n",
    "\n",
    "# example usage\n",
    "rdd_with_exemplars = rdd.mapPartitions(choose_exemplars)\n",
    "rdd_with_exemplars.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a538e",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da68b739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 3,\n",
       "  'time_series': [2.0, 2.5, 3.0, 3.5, 4.0],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5],\n",
       "  'dtw_distance_exemplar_1': 1.7320508075688772,\n",
       "  'dtw_distance_exemplar_2': 11.20267825120404,\n",
       "  'dtw_distance_exemplar_3': 0.7348469228349536,\n",
       "  'dtw_distance_exemplar_4': 1.6703293088490065},\n",
       " {'label': 4,\n",
       "  'time_series': [5.5, 6.6, 7.7, 8.8, 9.9],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5],\n",
       "  'dtw_distance_exemplar_1': 10.78424777163433,\n",
       "  'dtw_distance_exemplar_2': 0.7416198487095661,\n",
       "  'dtw_distance_exemplar_3': 11.244998888394788,\n",
       "  'dtw_distance_exemplar_4': 7.784600182411426},\n",
       " {'label': 4,\n",
       "  'time_series': [6.1, 6.2, 6.3, 6.4, 6.5],\n",
       "  'partition_id': 0,\n",
       "  'exemplar_1': [0.5, 1.5, 2.5, 3.5, 4.5],\n",
       "  'exemplar_2': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_3': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_4': [1.9, 2.8, 3.7, 4.6, 5.5],\n",
       "  'dtw_distance_exemplar_1': 8.96102672688794,\n",
       "  'dtw_distance_exemplar_2': 4.6097722286464435,\n",
       "  'dtw_distance_exemplar_3': 8.423182296495783,\n",
       "  'dtw_distance_exemplar_4': 6.268971207462991}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_dtw_distance(iterator):\n",
    "    partition_data = list(iterator)\n",
    "    updated_rows = []\n",
    "    \n",
    "    for row in partition_data:\n",
    "        time_series = row.get('time_series', [])\n",
    "        \n",
    "        # Check for individual exemplar columns (exemplar_1, exemplar_2, etc.)\n",
    "        exemplar_columns = {k: v for k, v in row.items() if k.startswith('exemplar_') and isinstance(v, list)}\n",
    "        \n",
    "        if not exemplar_columns:\n",
    "            # Try to get exemplars from the 'exemplars' list if individual columns aren't found\n",
    "            exemplars = row.get('exemplars', [])\n",
    "            if not exemplars:\n",
    "                continue  # Skip if no exemplars found\n",
    "            \n",
    "            # Calculate DTW distances for each exemplar in the list\n",
    "            updated_row = {**row}\n",
    "            for i, exemplar in enumerate(exemplars):\n",
    "                dtw_distance = dtw.distance(time_series, exemplar)\n",
    "                updated_row[f\"dtw_distance_exemplar_{i+1}\"] = dtw_distance\n",
    "            \n",
    "            updated_rows.append(updated_row)\n",
    "        else:\n",
    "            # Calculate DTW distances for each exemplar column\n",
    "            updated_row = {**row}\n",
    "            for col_name, exemplar in exemplar_columns.items():\n",
    "                # Extract index from column name (e.g., \"exemplar_1\" -> \"1\")\n",
    "                idx = col_name.split('_')[1]\n",
    "                dtw_distance = dtw.distance(time_series, exemplar)\n",
    "                updated_row[f\"dtw_distance_exemplar_{idx}\"] = dtw_distance\n",
    "            \n",
    "            updated_rows.append(updated_row)\n",
    "    \n",
    "    return iter(updated_rows)\n",
    "\n",
    "# example usage\n",
    "rdd_with_dtw = rdd_with_exemplars.mapPartitions(calc_dtw_distance)\n",
    "rdd_with_dtw.collect()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6deac",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "04397cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 3,\n",
       "  'time_series': [2.0, 2.5, 3.0, 3.5, 4.0],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [1.4, 2.0, 2.6, 3.2, 3.8]},\n",
       " {'label': 4,\n",
       "  'time_series': [5.5, 6.6, 7.7, 8.8, 9.9],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_2',\n",
       "  'closest_exemplar_data': [6.0, 7.0, 8.0, 9.0, 10.0]},\n",
       " {'label': 4,\n",
       "  'time_series': [6.1, 6.2, 6.3, 6.4, 6.5],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_2',\n",
       "  'closest_exemplar_data': [6.0, 7.0, 8.0, 9.0, 10.0]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.7, 1.3, 1.9, 2.5, 3.1],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [1.4, 2.0, 2.6, 3.2, 3.8]},\n",
       " {'label': 1,\n",
       "  'time_series': [1.1, 2.1, 3.1, 4.1, 5.1],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_4',\n",
       "  'closest_exemplar_data': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.6, 1.2, 1.8, 2.4, 3.0],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [1.4, 2.0, 2.6, 3.2, 3.8]},\n",
       " {'label': 2,\n",
       "  'time_series': [2.4, 3.5, 4.6, 5.7, 6.8],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_4',\n",
       "  'closest_exemplar_data': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 3,\n",
       "  'time_series': [1.0, 1.8, 2.6, 3.4, 4.2],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [1.4, 2.0, 2.6, 3.2, 3.8]},\n",
       " {'label': 1,\n",
       "  'time_series': [1.3, 2.3, 3.3, 4.3, 5.3],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_4',\n",
       "  'closest_exemplar_data': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.9, 1.4, 1.9, 2.4, 2.9],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [1.4, 2.0, 2.6, 3.2, 3.8]},\n",
       " {'label': 2,\n",
       "  'time_series': [2.2, 3.1, 4.0, 4.9, 5.8],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_4',\n",
       "  'closest_exemplar_data': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 2,\n",
       "  'time_series': [2.6, 3.2, 3.8, 4.4, 5.0],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_4',\n",
       "  'closest_exemplar_data': [1.9, 2.8, 3.7, 4.6, 5.5]},\n",
       " {'label': 3,\n",
       "  'time_series': [1.2, 2.0, 2.8, 3.6, 4.4],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [1.4, 2.0, 2.6, 3.2, 3.8]},\n",
       " {'label': 3,\n",
       "  'time_series': [0.6, 1.3, 2.0, 2.7, 3.4],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [1.4, 2.0, 2.6, 3.2, 3.8]},\n",
       " {'label': 4,\n",
       "  'time_series': [6.3, 6.5, 6.7, 6.9, 7.1],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_2',\n",
       "  'closest_exemplar_data': [6.0, 7.0, 8.0, 9.0, 10.0]},\n",
       " {'label': 4,\n",
       "  'time_series': [7.0, 7.8, 8.6, 9.4, 10.2],\n",
       "  'partition_id': 0,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_2',\n",
       "  'closest_exemplar_data': [6.0, 7.0, 8.0, 9.0, 10.0]},\n",
       " {'label': 1,\n",
       "  'time_series': [1.0, 1.8, 2.6, 3.4, 4.2],\n",
       "  'partition_id': 1,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [0.9, 1.7, 1.2, 2.4, 2.8]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.9, 1.8, 2.7, 3.6, 4.5],\n",
       "  'partition_id': 1,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_1',\n",
       "  'closest_exemplar_data': [1.2, 2.4, 3.6, 4.8, 6.0]},\n",
       " {'label': 1,\n",
       "  'time_series': [1.5, 2.1, 2.7, 3.3, 3.9],\n",
       "  'partition_id': 1,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [0.9, 1.7, 1.2, 2.4, 2.8]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.8, 1.7, 2.5, 3.2, 4.0],\n",
       "  'partition_id': 1,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [0.9, 1.7, 1.2, 2.4, 2.8]},\n",
       " {'label': 2,\n",
       "  'time_series': [2.1, 3.3, 4.5, 5.7, 6.9],\n",
       "  'partition_id': 1,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_2',\n",
       "  'closest_exemplar_data': [3.3, 4.1, 4.9, 5.7, 6.5]},\n",
       " {'label': 2,\n",
       "  'time_series': [3.0, 3.8, 4.6, 5.4, 6.2],\n",
       "  'partition_id': 1,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_2',\n",
       "  'closest_exemplar_data': [3.3, 4.1, 4.9, 5.7, 6.5]},\n",
       " {'label': 4,\n",
       "  'time_series': [6.5, 7.0, 7.5, 8.0, 8.5],\n",
       "  'partition_id': 1,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_2',\n",
       "  'closest_exemplar_data': [3.3, 4.1, 4.9, 5.7, 6.5]},\n",
       " {'label': 1,\n",
       "  'time_series': [0.5, 1.0, 1.5, 2.0, 2.5],\n",
       "  'partition_id': 1,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'closest_exemplar_data': [0.9, 1.7, 1.2, 2.4, 2.8]},\n",
       " {'label': 2,\n",
       "  'time_series': [0.6, 1.4, 1.3, 2.1, 2.5],\n",
       "  'partition_id': 1,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_4',\n",
       "  'closest_exemplar_data': [0.3, 1.7, 1.6, 2.2, 2.6]},\n",
       " {'label': 4,\n",
       "  'time_series': [0.2, 1.9, 1.6, 2.3, 2.7],\n",
       "  'partition_id': 1,\n",
       "  'closest_exemplar_id': 'dtw_distance_exemplar_4',\n",
       "  'closest_exemplar_data': [0.3, 1.7, 1.6, 2.2, 2.6]}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_closest_exemplar(iterator):\n",
    "    partition_data = list(iterator)\n",
    "    updated_rows = []\n",
    "    \n",
    "    for row in partition_data:\n",
    "        # Get all DTW distances\n",
    "        dtw_distances = {k: v for k, v in row.items() if k.startswith('dtw_distance_exemplar_')}\n",
    "        \n",
    "        if not dtw_distances:\n",
    "            # Create a simplified row without exemplar columns\n",
    "            simplified_row = {k: v for k, v in row.items() \n",
    "                             if not k.startswith('exemplar_')}\n",
    "            updated_rows.append(simplified_row)\n",
    "            continue\n",
    "        \n",
    "        # Find the closest exemplar based on the minimum DTW distance\n",
    "        closest_exemplar_key = min(dtw_distances, key=dtw_distances.get)\n",
    "        min_distance = dtw_distances[closest_exemplar_key]\n",
    "        \n",
    "        # Extract exemplar number from the key (e.g., \"dtw_distance_exemplar_1\" -> \"1\")\n",
    "        exemplar_num = closest_exemplar_key.split('_')[-1]\n",
    "        \n",
    "        # Get the corresponding exemplar time series data\n",
    "        exemplar_key = f'exemplar_{exemplar_num}'\n",
    "        exemplar_time_series = row.get(exemplar_key, None)\n",
    "        \n",
    "        # Create a new row without the DTW distance columns and exemplar columns\n",
    "        updated_row = {k: v for k, v in row.items() \n",
    "                      if not k.startswith('dtw_distance_exemplar_') and not k.startswith('exemplar_')}\n",
    "        \n",
    "        # Add information about the closest exemplar\n",
    "        updated_row['closest_exemplar_id'] = closest_exemplar_key\n",
    "        # updated_row['closest_exemplar_distance'] = min_distance\n",
    "        updated_row['closest_exemplar_data'] = exemplar_time_series\n",
    "        \n",
    "        updated_rows.append(updated_row)\n",
    "    \n",
    "    return iter(updated_rows)\n",
    "\n",
    "# Example usage\n",
    "rdd_with_closest_exemplar = rdd_with_dtw.mapPartitions(assign_closest_exemplar)\n",
    "rdd_with_closest_exemplar.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471e7d5",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f9daa07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'partition_id': 0,\n",
       "  'exemplar_id': 'dtw_distance_exemplar_4',\n",
       "  'exemplar_data': [1.9, 2.8, 3.7, 4.6, 5.5],\n",
       "  'exemplar_label': 1,\n",
       "  'gini_reduction': 0.1376420454545454},\n",
       " {'partition_id': 0,\n",
       "  'exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'exemplar_data': [1.4, 2.0, 2.6, 3.2, 3.8],\n",
       "  'exemplar_label': 3,\n",
       "  'gini_reduction': 0.16679067460317454},\n",
       " {'partition_id': 0,\n",
       "  'exemplar_id': 'dtw_distance_exemplar_2',\n",
       "  'exemplar_data': [6.0, 7.0, 8.0, 9.0, 10.0],\n",
       "  'exemplar_label': 4,\n",
       "  'gini_reduction': 0.25260416666666663},\n",
       " {'partition_id': 1,\n",
       "  'exemplar_id': 'dtw_distance_exemplar_4',\n",
       "  'exemplar_data': [0.3, 1.7, 1.6, 2.2, 2.6],\n",
       "  'exemplar_label': 2,\n",
       "  'gini_reduction': 0.09499999999999997},\n",
       " {'partition_id': 1,\n",
       "  'exemplar_id': 'dtw_distance_exemplar_1',\n",
       "  'exemplar_data': [1.2, 2.4, 3.6, 4.8, 6.0],\n",
       "  'exemplar_label': 1,\n",
       "  'gini_reduction': 0.04222222222222227},\n",
       " {'partition_id': 1,\n",
       "  'exemplar_id': 'dtw_distance_exemplar_3',\n",
       "  'exemplar_data': [0.9, 1.7, 1.2, 2.4, 2.8],\n",
       "  'exemplar_label': 1,\n",
       "  'gini_reduction': 0.2533333333333333},\n",
       " {'partition_id': 1,\n",
       "  'exemplar_id': 'dtw_distance_exemplar_2',\n",
       "  'exemplar_data': [3.3, 4.1, 4.9, 5.7, 6.5],\n",
       "  'exemplar_label': 2,\n",
       "  'gini_reduction': 0.1723809523809524}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_gini(labels):\n",
    "    if not labels:\n",
    "        return 0\n",
    "    label_counts = {}\n",
    "    for label in labels:\n",
    "        label_counts[label] = label_counts.get(label, 0) + 1\n",
    "    total = sum(label_counts.values())\n",
    "    gini = 1 - sum((count / total) ** 2 for count in label_counts.values()) if total > 0 else 0\n",
    "    return gini\n",
    "\n",
    "def evaluate_splits_within_partition(index, iterator):\n",
    "    partition_data = list(iterator)\n",
    "    results = []\n",
    "    \n",
    "    # Calculate Gini impurity before splitting\n",
    "    labels = [row.get('label') for row in partition_data if row.get('label') is not None]\n",
    "    before_split_gini = calculate_gini(labels)\n",
    "    \n",
    "    # Get all unique exemplars in the partition\n",
    "    unique_exemplars = set(\n",
    "        row['closest_exemplar_id'] for row in partition_data\n",
    "        if row.get('closest_exemplar_id') is not None\n",
    "    )\n",
    "    \n",
    "    # Create a mapping of exemplar_id to exemplar_data and exemplar_label\n",
    "    exemplar_data_map = {}\n",
    "    exemplar_label_map = {}\n",
    "    \n",
    "    for row in partition_data:\n",
    "        exemplar_id = row.get('closest_exemplar_id')\n",
    "        if exemplar_id and exemplar_id not in exemplar_data_map:\n",
    "            exemplar_data_map[exemplar_id] = row.get('closest_exemplar_data')\n",
    "            # Find the label of the exemplar itself\n",
    "            # This assumes the first row with this exemplar_id has the correct label\n",
    "            exemplar_label_map[exemplar_id] = row.get('label')\n",
    "    \n",
    "    # Evaluate all possible splits\n",
    "    for exemplar_id in unique_exemplars:\n",
    "        # Split the data based on the current exemplar\n",
    "        yes_split = [r for r in partition_data if r.get('closest_exemplar_id') == exemplar_id]\n",
    "        no_split = [r for r in partition_data if r.get('closest_exemplar_id') != exemplar_id]\n",
    "        \n",
    "        # Calculate Gini for each daughter node\n",
    "        yes_labels = [r.get('label') for r in yes_split if r.get('label') is not None]\n",
    "        no_labels = [r.get('label') for r in no_split if r.get('label') is not None]\n",
    "        \n",
    "        yes_gini = calculate_gini(yes_labels)\n",
    "        no_gini = calculate_gini(no_labels)\n",
    "        \n",
    "        # Calculate weighted Gini after split\n",
    "        total_size = len(yes_split) + len(no_split)\n",
    "        weighted_gini = (yes_gini * len(yes_split) / total_size + no_gini * len(no_split) / total_size) if total_size > 0 else float('inf')\n",
    "        \n",
    "        # Calculate Gini reduction\n",
    "        gini_reduction = before_split_gini - weighted_gini if total_size > 0 else float('-inf')\n",
    "        \n",
    "        # Get the exemplar data and label for this exemplar_id\n",
    "        exemplar_data = exemplar_data_map.get(exemplar_id)\n",
    "        exemplar_label = exemplar_label_map.get(exemplar_id)\n",
    "        \n",
    "        # Add this split evaluation to results\n",
    "        results.append({\n",
    "            \"partition_id\": index,\n",
    "            \"exemplar_id\": exemplar_id,\n",
    "            \"exemplar_data\": exemplar_data,\n",
    "            \"exemplar_label\": exemplar_label,\n",
    "            \"gini_reduction\": gini_reduction   \n",
    "        })\n",
    "    \n",
    "    return iter(results)\n",
    "\n",
    "# Example usage\n",
    "rdd_with_splits = rdd_with_closest_exemplar.mapPartitionsWithIndex(evaluate_splits_within_partition)\n",
    "rdd_with_splits.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "67b878db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree_node(exemplar_evaluations):\n",
    "    \"\"\"\n",
    "    Find the best exemplar across all evaluations to use for splitting.\n",
    "    \n",
    "    Parameters:\n",
    "    - exemplar_evaluations: List of dicts containing exemplar evaluation results\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with best split information\n",
    "    \"\"\"\n",
    "    # Find the best exemplar across all partitions (highest gini_reduction)\n",
    "    best_exemplar = max(exemplar_evaluations, key=lambda x: x['gini_reduction'])\n",
    "    \n",
    "    # Create a decision node\n",
    "    node = {\n",
    "        'split_feature': best_exemplar['exemplar_id'],\n",
    "        'split_value': best_exemplar['exemplar_data'],\n",
    "        'exemplar_label': best_exemplar['exemplar_label'],\n",
    "        'gini_reduction': best_exemplar['gini_reduction']\n",
    "    }\n",
    "    \n",
    "    return node\n",
    "\n",
    "def split_data_by_exemplar(best_exemplar_id):\n",
    "    \"\"\"\n",
    "    Returns a function that can be used with mapPartitions to split data based on the best exemplar.\n",
    "    \n",
    "    Parameters:\n",
    "    - best_exemplar_id: ID of the best exemplar to split on\n",
    "    \n",
    "    Returns:\n",
    "    - A function for use with mapPartitions\n",
    "    \"\"\"\n",
    "    def split_partition(iterator):\n",
    "        yes_branch = []\n",
    "        no_branch = []\n",
    "        \n",
    "        for row in iterator:\n",
    "            if row.get('closest_exemplar_id') == best_exemplar_id:\n",
    "                # Add branch indicator\n",
    "                row_with_branch = row.copy()\n",
    "                row_with_branch['branch'] = 'yes'\n",
    "                yes_branch.append(row_with_branch)\n",
    "            else:\n",
    "                # Add branch indicator\n",
    "                row_with_branch = row.copy()\n",
    "                row_with_branch['branch'] = 'no'\n",
    "                no_branch.append(row_with_branch)\n",
    "        \n",
    "        # Return all rows with branch indicators\n",
    "        return iter(yes_branch + no_branch)\n",
    "    \n",
    "    return split_partition\n",
    "\n",
    "# Example usage:\n",
    "# 1. Collect the exemplar evaluations\n",
    "exemplar_evaluations = rdd_with_splits.collect()\n",
    "\n",
    "# 2. Find the best exemplar\n",
    "node = build_decision_tree_node(exemplar_evaluations)\n",
    "\n",
    "# 3. Use the best exemplar to split the data\n",
    "split_fn = split_data_by_exemplar(node['split_feature'])\n",
    "rdd_with_branch = rdd_with_closest_exemplar.mapPartitions(split_fn)\n",
    "\n",
    "# 4. Now you can separate the yes/no branches if needed\n",
    "yes_branch = rdd_with_branch.filter(lambda x: x.get('branch') == 'yes')\n",
    "no_branch = rdd_with_branch.filter(lambda x: x.get('branch') == 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4104c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'split_feature': 'dtw_distance_exemplar_1',\n",
       " 'split_value': [1.0, 1.8, 2.6, 3.4, 4.2],\n",
       " 'gini_reduction': 0.23645128205128213,\n",
       " 'is_leaf': False,\n",
       " 'left_child': None,\n",
       " 'right_child': None}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9275b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
